\Citeauthor{florence2018dense}~\cite{florence2018dense} introduced the Pixelwise Contrastive loss function to train DON,
which involves sampling pixels in an image-pair and computing the Contrastive loss between the pixels in the first image
and those in the second image. This optimization procedure aims to improve the descriptor based on a similarity metric.
However, the Pixelwise Contrastive loss function is computationally expensive and requires numerous matching and non-matching
image-pair correspondences to work optimally. When optimizing DON using a large number ($N$) of image-pair correspondences,
the computational resources consumed by the optimization procedure increase significantly due to the exponential growth of
pixelwise descriptor similarity comparisons ($2^N$).

In their work, \citeauthor{florence2020dense}~\cite{florence2020dense} discovered that the Pixelwise Contrastive loss
function used to train DON might yield poor performance if a computed correspondence is spatially inconsistent.
They also highlighted that the precision of contrastive-trained models could be sensitive to the relative weighting
between positive and negative sampled pixels. To address these limitations, \citeauthor{florence2020dense}
proposed a new continuous sampling-based loss function called the Pixelwise Distribution loss. This novel
loss function leverages smooth and continuous pixel space sampling instead of the discrete pixel space
sampling method employed by the Pixelwise Contrastive loss. The Pixelwise Distribution loss eliminates
the need for non-matching correspondences, leading to significant savings in computation resources.

On a different note, \citeauthor{kupcsik2021supervised}~\cite{kupcsik2021supervised} utilized Laplacian Eigenmaps~\cite{belkin2003laplacian}
to embed a 3D object model into an optimally generated embedding space, serving as the target for training DON in a supervised fashion.
However, this methodology does not reduce the computational resource consumption required to train DON. In contrast,
\citeauthor{hadjivelichkov2021fully}~\cite{hadjivelichkov2021fully} employed offline unsupervised clustering based on confidence
in object similarities to generate hard and soft correspondence labels. These labels were then used as matching and non-matching
correspondences to train DON effectively.

Building upon the concept of SIMCLR-inspired frameworks~\parencites{chen2020simple}{zbontar2021barlow},
\citeauthor{adrian2022efficient}~\cite{adrian2022efficient} introduced a similar architecture and another
novel loss function called the Pixelwise NTXent Loss. This loss function robustly trains DON by leveraging
synthetic correspondences computed from image augmentations and non-matching image correspondences.
Notably, \citeauthor{adrian2022efficient}'s experiments demonstrated that the novel loss function is
invariant to batch size variations, unlike the Pixelwise Contrastive Loss. Furthermore, it is worth
noting that most of the discussed optimization methodologies heavily rely on correspondences to train DON effectively.

Moving on to the aspect of image-pair correspondences and dataset engineering,
the DON training strategy proposed in \cite{florence2018dense, florence2020dense} relies on depth information to
compute correspondences between image pairs using camera intrinsics and pose information \cite{hartley2003multiple}.
However, when utilizing consumer-grade depth cameras to capture depth information, the resulting depth data can be noisy,
particularly when dealing with tiny, reflecting objects common in industrial environments. Noisy depth information hampers
the computation of consistent spatial correspondences in an image pair. To overcome this challenge,
\citeauthor{kupcsik2021supervised}~\cite{kupcsik2021supervised} associated 3D models of objects with image views,
effectively training DON without relying on depth information. Their approach proved efficient for smaller,
texture-less, and reflective objects. Additionally, \citeauthor{kupcsik2021supervised}
compared different training strategies for producing 6D grasps on industrial objects and
demonstrated that a unique supervised training approach enhances pick-and-place resilience in industry-relevant tasks.

In contrast, \citeauthor{nerf-Supervision}\cite{nerf-Supervision} employed NeRF\cite{mildenhall2021nerf},
a method that reconstructs a 3D scene from a sequence of images captured by a smartphone camera.
They extracted correspondences from the synthetically reconstructed scene to train DON. Remarkably,
\citeauthor{adrian2022efficient}'s experiments indicated that DON trained on synthetic data generalizes
well to real-world objects. Furthermore, they adopted the $PCK@k$ metric, commonly used in
\parencites{chai2019multi}{fathy2018hierarchical}, to evaluate and benchmark DON's performance
in cluttered scenes that were previously not extensively studied.

In our work, we do not use any loss functions as proposed in \parencites{florence2018dense}{florence2020dense}{kupcsik2021supervised}{adrian2022efficient}{hadjivelichkov2021fully}{nerf-Supervision}
to train DON. However, we adopt the network architecture from DON~\cite{florence2018dense}
as our architecture's backbone and train on the task of the KeypointNet\parencites{suwajanakorn2018discovery}{zhao2020learning}
with few network modifications. Moreover, we evaluate the descriptor's robustness produced by our framework on the $PCK@k$ metric as in comparision
to benchmarks in \cite{adrian2022efficient} as it is the only benchmark available for DON. Furthermore, we compare the computational resource consumption.