Creating a general-purpose robotic system capable of performing practical tasks, such as those portrayed
in movies like Chappie~\cite{blomkamp2015chappie} or C-3PO~\cite{lucas1977star}, is a significant challenge in robotics.
While advancements have been made in related domains, achieving this goal remains an ongoing endeavour.
Recent artificial intelligence (AI) breakthroughs, particularly in deep learning, have demonstrated remarkable capabilities.
For instance, AlphaGo~\cite{silver2018general}, an AI system trained entirely on self-play, defeated the world's best human
Go player at the time. Subsequent algorithms, such as those developed by \citeauthor{silver2016mastering}~\cite{silver2016mastering},
have mastered complex games like chess, Go, World of Warcraft~\cite{entertainment2013world},
and Shogi, surpassing human expertise. These achievements underscore the importance of visual data in
deep learning, as these algorithms learn directly from visual inputs like gameplay recordings or online video streams.
Additionally, the introduction of AlexNet~\cite{krizhevsky2017imagenet} in 2012 has revolutionized computer vision,
leading to significant progress in tasks like semantic segmentation~\cite{long2015fully}, object identification
and recognition~\cite{he2017mask}, and human pose estimation~\cite{guler2018densepose}.

Significant strides have been made in robotics, including self-driving cars and humanoid robots with advanced capabilities.
Integration of AI models like ChatGPT~\cite{openai2023gpt4} and PaLM~\cite{palm}
enhances human-robot interactions and object perception. However, deploying Large Language Models (LLMs)
such as ChatGPT and Palm-E poses challenges.
Their size and complexity require substantial computational resources,
raising concerns about energy consumption, environmental impact,
and the digital divide~\cite{bender2021dangers,strubell2019energy}.
Responsible resource allocation and addressing ethical implications are crucial for balancing progress and sustainability.

Currently, in robotics, typical industrial robots perform repetitive operations based on pre-programmed instructions,
finding the ideal object representation for grasping and manipulation tasks still needs to be answered.
Existing representations may be unable to understand an object's geometrical and structural information, rendering them unsuitable for complex tasks
In recent work, \citeauthor{florence2018dense}~\cite{florence2018dense} introduced a novel visual object representation termed "dense visual object descriptors" to the robotics community.
This representation, generated by the Dense Object Nets (DON) framework, converts each pixel in an image ($I[u, v] \in \mathbb{R}^3$)
into a higher-dimensional embedding ($I_D[u, v] \in \mathbb{R}^D$) such that $D \in \mathbb{N}^+$,
using image-pair correspondences as input. These dense visual object descriptors provide a generalized representation of objects to a certain extent.


The DON framework has shown promise in various domains, including rope manipulation~\cite{rope-manipulation},
block manipulation~\cite{block-manipulation}, robot control~\cite{florence2019self}, fabric manipulation~\cite{fabric-manipulation},
and robot grasp pose estimation~\parencites{kupcsik2021supervised}{adrian2022efficient}. \citeauthor{adrian2022efficient}~\cite{adrian2022efficient}
demonstrated that DON can be trained on
synthetic data and still generalize well to real-world objects. Furthermore, they highlighted the importance of the
dimensionality of the embedding in determining the quality of the descriptors produced by the DON framework.


In this paper, we address the challenge posed by the computationally intensive nature of DON and propose a new framework for training DON
in a computationally efficient manner. Furthermore, we introduce a novel synthetic data generation pipeline that generates a complete dataset
from one image and mask pair. Additionally, the synthetic data generation pipeline does not rely on the noisy depth information produced by
today's consumer-grade depth cameras. We also demonstrate one of the applications of our framework as a robotic grasping pipeline.
Our approach aims to contribute to developing a sustainable and efficient, and economical solution for industrial robotics applications.