\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2020

% ready for submission
% \usepackage{neurips_2020}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2020}

% to compile a camera-ready version, add the [final] option, e.g.:
% \usepackage[final]{neurips_2020}

% to avoid loading the natbib package, add option nonatbib:
\usepackage[nonatbib]{neurips_2023}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tabless
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{amsmath}
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{cleveref}       % smart cross-referencing
\usepackage{graphicx}
\usepackage[english]{babel}
\usepackage{csquotes}
\usepackage{multirow}




% Bibliography
\usepackage[%
  backend=biber,%
  backref=false,%
  giveninits=true,%
  autocite=inline,%
  sorting=none,% in order of occurence. Other option: nyt (name year title)
  sortcites=true,%
  mincitenames=1,%
  maxcitenames=2,%
  maxbibnames=10,%
  doi=true,%
  isbn=false,%
  url=false,%
  natbib=false,
]{biblatex}

\renewcommand*{\bibfont}{\small}
\addbibresource{neurips_2020.bib}

\title{Training Dense Object Nets: A Novel Approach}

\author{%
  Kanishk Navale\textsuperscript{1}\thanks{for correspondence: kanishk.navale@sereact.ai}, \quad
  Ralf Gulde\textsuperscript{1, 2}, \quad
  Marc Tuscher\textsuperscript{1}, \quad
  Oliver Riedel \textsuperscript{2}\\
  \textsuperscript{1}Sereact GmbH, Stuttgart, Germany \quad
  \textsuperscript{2}ISW, Universit√§t Stuttgart, Stuttgart, Germany\\
}

\begin{document}



\maketitle

\begin{abstract}
  Our work proposes a novel framework that addresses the computational limitations associated with training Dense Object Nets (DON)
  while achieving robust and dense visual object descriptors. DON's descriptors are known for their robustness to
  viewpoint and configuration changes, but training these requires image pairs with computationally expensive correspondence mapping.
  This limitation hampers dimensionality and robustness, thereby restricting object generalization.
  To overcome this, we introduce data generation procedure using synthetic augmentation and a novel deep learning architecture
  that produces denser visual descriptors with reduced computational demands. Notably, our framework eliminates the need for
  image pair correspondence mapping and showcases its application in a robotic grasping pipeline.
  Experimental results demonstrate that our approach yields descriptors as robust as those generated by DON.
  % you say these are denser, why as dense as here?
\end{abstract}

\section{Introduction}
\input{chapters/introduction.tex}

\section{Related Work}
\input{chapters/related.tex}

\section{Methodology}
\input{chapters/methodology.tex}

\section{Experiments \& Results}
\input{chapters/results.tex}

\section{Conclusion}
\input{chapters/conclusion.tex}


\printbibliography

\end{document}
